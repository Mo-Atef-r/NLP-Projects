{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc49a0dd",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "This project utilizes the IMDB Large Movie Review Dataset introduced by Maas et al. (2011) in their paper \"Learning Word Vectors for Sentiment Analysis.\" The dataset consists of 50,000 movie reviews collected from IMDB, equally divided into 25,000 training and 25,000 test samples, with balanced classes for binary sentiment classification (positive and negative). Each review is preprocessed and labeled, making it a standard benchmark for evaluating sentiment analysis models. This dataset is widely used for exploring natural language processing techniques, especially in tasks involving text classification, embedding learning, and sentiment prediction.\n",
    "\n",
    "#### Reference\n",
    "__Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). Learning word vectors for sentiment analysis. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, 142â€“150. http://www.aclweb.org/anthology/P11-1015__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae01dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e2ff678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38707d2e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df78f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHKAR SHOW\\AppData\\Local\\Temp\\ipykernel_7052\\3878026251.py:4: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    }
   ],
   "source": [
    "#this cell reads the dataset in its original path and extracts it to the project folder\n",
    "#data_path = r\"D:\\Data_and_AI\\Datasets\\Large Movie Review Dataset\\aclImdb_v1.tar.gz\"\n",
    "#with tarfile.open(data_path, 'r:gz') as tar:\n",
    "#    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a2730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(directory):\n",
    "    # Get all .txt files in pos/neg subdirectories\n",
    "    pos_files = glob(os.path.join(directory, 'pos', '*.txt'))\n",
    "    neg_files = glob(os.path.join(directory, 'neg', '*.txt'))\n",
    "    all_files = pos_files + neg_files\n",
    "    \n",
    "    # Read files in parallel (I/O-bound)\n",
    "    def read_file(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        label = 'pos' if 'pos' in file_path else 'neg'\n",
    "        return (text, label)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        data = list(executor.map(read_file, all_files))\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bec9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000, 2)\n",
      "Test data shape: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = load_files('aclImdb/train')\n",
    "test_df = load_files('aclImdb/test')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "426ec81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   pos\n",
       "1  Homelessness (or Houselessness as George Carli...   pos\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...   pos\n",
       "3  This is easily the most underrated film inn th...   pos\n",
       "4  This is not the typical Mel Brooks film. It wa...   pos"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Data\\n\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d090c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  I went and saw this movie last night after bei...   pos\n",
       "1  Actor turned director Bill Paxton follows up h...   pos\n",
       "2  As a recreational golfer with some knowledge o...   pos\n",
       "3  I saw this film in a sneak preview, and it is ...   pos\n",
       "4  Bill Paxton has taken the true story of the 19...   pos"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Data\\n\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd666a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43c909e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a sample review\n"
     ]
    }
   ],
   "source": [
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = clean_html(text)\n",
    "    #substitute any non (^) alphabet characters lower or upper (a-zA-Z) or whitespace (\\s) with empty string ('')\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    # Replace any one or more spaces (+) with one space (' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example:\n",
    "sample_text = \"This is a <b>sample</b> review!!! ðŸ˜Š\"\n",
    "print(clean_text(sample_text))  # Output: \"this is a sample review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00b70203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'sample', 'review']\n"
     ]
    }
   ],
   "source": [
    "text = \"this is a sample review\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)  # Output: ['this', 'is', 'a', 'sample', 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ceee0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'review']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "tokens = ['this', 'is', 'a', 'sample', 'review']\n",
    "filtered_tokens = remove_stopwords(tokens)\n",
    "print(filtered_tokens)  # Output: ['sample', 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e57f6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'dog', 'ate']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "tokens = ['running', 'dogs', 'ate']\n",
    "lemmatized = lemmatize(tokens)\n",
    "print(lemmatized)  # Output: ['running', 'dog', 'ate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aa2ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full preprocessing pipeline\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Clean HTML and special characters\n",
    "    text = clean_text(text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    # Lemmatize\n",
    "    tokens = lemmatize(tokens)\n",
    "    return ' '.join(tokens)  # Return as a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "698eab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHKAR SHOW\\AppData\\Local\\Temp\\ipykernel_7052\\3964667044.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, 'html.parser').get_text()\n",
      "C:\\Users\\SHKAR SHOW\\AppData\\Local\\Temp\\ipykernel_7052\\3964667044.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, 'html.parser').get_text()\n"
     ]
    }
   ],
   "source": [
    "#preprocess training and test data\n",
    "train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['processed_text'] = test_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4748751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>bromwell high cartoon comedy ran time program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>pos</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>pos</td>\n",
       "      <td>brilliant overacting lesley ann warren best dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>pos</td>\n",
       "      <td>easily underrated film inn brook cannon sure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>pos</td>\n",
       "      <td>typical mel brook film much less slapstick mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   pos   \n",
       "1  Homelessness (or Houselessness as George Carli...   pos   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...   pos   \n",
       "3  This is easily the most underrated film inn th...   pos   \n",
       "4  This is not the typical Mel Brooks film. It wa...   pos   \n",
       "\n",
       "                                      processed_text  \n",
       "0  bromwell high cartoon comedy ran time program ...  \n",
       "1  homelessness houselessness george carlin state...  \n",
       "2  brilliant overacting lesley ann warren best dr...  \n",
       "3  easily underrated film inn brook cannon sure f...  \n",
       "4  typical mel brook film much less slapstick mov...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1563f8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>pos</td>\n",
       "      <td>went saw movie last night coaxed friend mine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>pos</td>\n",
       "      <td>actor turned director bill paxton follows prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>pos</td>\n",
       "      <td>recreational golfer knowledge sport history pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>saw film sneak preview delightful cinematograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>pos</td>\n",
       "      <td>bill paxton taken true story u golf open made ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  I went and saw this movie last night after bei...   pos   \n",
       "1  Actor turned director Bill Paxton follows up h...   pos   \n",
       "2  As a recreational golfer with some knowledge o...   pos   \n",
       "3  I saw this film in a sneak preview, and it is ...   pos   \n",
       "4  Bill Paxton has taken the true story of the 19...   pos   \n",
       "\n",
       "                                      processed_text  \n",
       "0  went saw movie last night coaxed friend mine i...  \n",
       "1  actor turned director bill paxton follows prom...  \n",
       "2  recreational golfer knowledge sport history pl...  \n",
       "3  saw film sneak preview delightful cinematograp...  \n",
       "4  bill paxton taken true story u golf open made ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba461a",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac724597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Bag-of-Words (BoW) Features\n",
    "bow_vectorizer = CountVectorizer(max_features=5000) \n",
    "# max_features limits vocabulary size to the most frequeny 5000 words in the corpus\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_df['processed_text'])\n",
    "X_test_bow = bow_vectorizer.transform(test_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc0a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TF-IDF Features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# Here, max_features limits the vocabulary to the top N words with the highest TF-IDF scores (not raw frequency)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['processed_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b689e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0bf21",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983a240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model_name, X_train, X_test, y_train, y_test):\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef6e4134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression with BoW ===\n",
      "Accuracy: 0.8438\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.85      0.85     12500\n",
      "         pos       0.85      0.83      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. BoW Model\n",
    "train_evaluate_model(\"Logistic Regression with BoW\", X_train_bow, X_test_bow, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f76c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression with TF-IDF ===\n",
      "Accuracy: 0.8773\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.87      0.88     12500\n",
      "         pos       0.87      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. TF-IDF Model\n",
    "train_evaluate_model(\"Logistic Regression with TF-IDF\", X_train_tfidf, X_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e2e6c",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9767cd",
   "metadata": {},
   "source": [
    "### 5-fold Cross Validation\n",
    "The training data is split into 5 equal parts (folds).\n",
    "\n",
    "The model is trained on 4 folds and validated on the remaining 1 fold.\n",
    "\n",
    "This process repeats 5 times, with each fold serving as the validation set once.\n",
    "\n",
    "Performance metrics (e.g., accuracy) are averaged across all 5 runs to estimate generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ba820b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1.0\n",
      "Best Training Accuracy: 0.85796\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [0.01, 0.1, 1.0, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), params, cv=5) #cv=5 is a 5-fold crossvalidation\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Best C:\", grid.best_params_['C'])  # e.g., C=1.0\n",
    "print(\"Best Training Accuracy:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11f308",
   "metadata": {},
   "source": [
    "### C is a hyperparameter, it's the inverse of regularization strength, so a smaller C means a stronger regularization. its default value is actually 1.0 (which turns out to result in the best accuracy)\n",
    "### Since the 5-fold cross validation averages the validation accuracies over the 5 iterations, it gives a more conservative estimate of accuracy than just one run for the model, that's why we end up with 85% validation accuracy as opposed to 87% we get when we evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d33c75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with best C: 0.8773\n"
     ]
    }
   ],
   "source": [
    "# After running GridSearchCV:\n",
    "best_model = grid.best_estimator_  # Get the model with best C\n",
    "test_accuracy = best_model.score(X_test_tfidf, y_test)\n",
    "print(f\"Test accuracy with best C: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2d34e",
   "metadata": {},
   "source": [
    "### Using N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47cecf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bigrams/trigrams\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),  # Unigrams, Bigrams, and Trigrams\n",
    "    max_features=15000,   # Top 15000 terms by TF-IDF score\n",
    "    sublinear_tf=True     # Apply sublinear scaling (log(1 + tf))\n",
    ")\n",
    "X_train_tfidf_ngram = tfidf.fit_transform(train_df['processed_text'])\n",
    "X_test_tfidf_ngram = tfidf.transform(test_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d82a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to tune\n",
    "params = {\n",
    "    'C': [0.1, 1.0, 10],  # Regularization strength\n",
    "    'penalty': ['l2'],      # L2 regularization (default)\n",
    "}\n",
    "\n",
    "# Search for best parameters\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "grid = GridSearchCV(lr, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train_tfidf_ngram, y_train)\n",
    "\n",
    "print(f\"Best C: {grid.best_params_['C']}\")  # e.g., C=10\n",
    "best_lr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4b1c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM C: 0.1\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.1, 1.0, 10],\n",
    "}\n",
    "\n",
    "svm = LinearSVC(random_state=42, max_iter=10000) #Support Vector Classification\n",
    "grid_svm = GridSearchCV(svm, params, cv=5, scoring='accuracy')\n",
    "grid_svm.fit(X_train_tfidf_ngram, y_train)\n",
    "\n",
    "print(f\"Best SVM C: {grid_svm.best_params_['C']}\")  # e.g., C=0.1\n",
    "best_svm = grid_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b9352",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0968b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.88      0.89     12500\n",
      "         pos       0.89      0.89      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n",
      "\n",
      "SVM Accuracy: 0.8896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.88      0.89     12500\n",
      "         pos       0.89      0.89      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "y_pred_lr = best_lr.predict(X_test_tfidf_ngram)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM\n",
    "y_pred_svm = best_svm.predict(X_test_tfidf_ngram)\n",
    "print(f\"\\nSVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7da7b",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "See the most impactful words for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36d14381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Words: ['great', 'excellent', 'perfect', 'wonderful', 'best', 'favorite', 'amazing', 'loved', 'today', 'fun']\n",
      "Top Negative Words: ['worst', 'bad', 'awful', 'waste', 'boring', 'poor', 'nothing', 'terrible', 'dull', 'worse']\n"
     ]
    }
   ],
   "source": [
    "# For Logistic Regression\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = best_lr.coef_[0]\n",
    "top_positive = [feature_names[i] for i in coefs.argsort()[-10:][::-1]]  # e.g., ['excellent', 'best']\n",
    "top_negative = [feature_names[i] for i in coefs.argsort()[:10]]         # e.g., ['worst', 'awful']\n",
    "print(\"Top Positive Words:\", top_positive)\n",
    "print(\"Top Negative Words:\", top_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd0207",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This project focuses on building and evaluating sentiment analysis models using the IMDB Large Movie Review Dataset introduced by Maas et al. (2011). The dataset contains 50,000 labeled movie reviews split evenly between positive and negative sentiment classes, making it ideal for binary text classification.\n",
    "\n",
    "The pipeline begins with thorough text preprocessing, including HTML tag removal, lowercasing, punctuation removal, stopword elimination, and lemmatization. Two main types of textual features are extracted:\n",
    "\n",
    "Bag-of-Words (BoW): Using a CountVectorizer with a vocabulary size limited to the top 5,000 most frequent terms.\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency): Captures term importance across documents with the same 5,000-word limit. An extended version with unigrams, bigrams, and trigrams (n-grams up to size 3) and 15,000 features is also explored.\n",
    "\n",
    "Two classification algorithms are trained and evaluated:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Linear Support Vector Machine (SVM)\n",
    "\n",
    "Initial models using BoW and TF-IDF achieved accuracies of 84.38% and 87.73%, respectively. Further performance improvements were achieved through hyperparameter tuning using 5-fold cross-validation and the inclusion of n-gram features. The final models reached accuracies of:\n",
    "\n",
    "Logistic Regression: 88.87%\n",
    "\n",
    "SVM: 88.96%\n",
    "\n",
    "The project also includes interpretability analysis by extracting the most influential positive and negative words based on the Logistic Regression modelâ€™s coefficients. This provides insights into the linguistic patterns associated with each sentiment class.\n",
    "\n",
    "Overall, the project demonstrates the effectiveness of traditional machine learning approaches for sentiment analysis when combined with careful preprocessing, feature engineering, and model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45954e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
