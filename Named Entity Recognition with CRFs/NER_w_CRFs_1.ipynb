{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3966616d",
   "metadata": {},
   "source": [
    "# Dataset  \n",
    "This notebook uses the **CoNLL-2003** dataset for Named Entity Recognition (NER) using Conditional Random Fields (CRFs).\n",
    "\n",
    "> **Citation:**  \n",
    "> Sang, E. F., & De Meulder, F. (2003). *Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition.* In Proceedings of the Seventh Conference on Natural Language Learning (CoNLL-2003) (pp. 142–147).  \n",
    ">  \n",
    "> **Dataset Link:** [https://www.clips.uantwerpen.be/conll2003/ner/](https://www.clips.uantwerpen.be/conll2003/ner/)  \n",
    "\n",
    "The dataset consists of annotated text for NER, with four entity types:  \n",
    "- **PER** (Person)  \n",
    "- **ORG** (Organization)  \n",
    "- **LOC** (Location)  \n",
    "- **MISC** (Miscellaneous)\n",
    "#### The entity tags use Beginning-Inside-Outside (BIO) tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d14674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14d38b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|█████████████████████████████████████████████████████████████| 983k/983k [00:00<00:00, 1.10MB/s]\n",
      "Generating train split: 100%|███████████████████████████████████████████| 14041/14041 [00:02<00:00, 6964.89 examples/s]\n",
      "Generating validation split: 100%|████████████████████████████████████████| 3250/3250 [00:00<00:00, 6306.18 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████████| 3453/3453 [00:00<00:00, 6115.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load with trust_remote_code=True\n",
    "conll2003 = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Inspect the structure\n",
    "print(conll2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ead584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect first sample\n",
    "print(conll2003[\"train\"][0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c2f9a",
   "metadata": {},
   "source": [
    "## POS Tags  \n",
    "Part-of-Speech tags identify the grammatical category of each word in a sentence based on its definition and context. These tags follow the Penn Treebank tagset and are fundamental for syntactic analysis. They distinguish between nouns, verbs, adjectives, prepositions, and other linguistic elements that define a word's role in sentence structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "544a5fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "pos_tag_names = conll2003[\"train\"].features[\"pos_tags\"].feature.names\n",
    "print(conll2003[\"train\"][0]['tokens']) \n",
    "print([pos_tag_names[tag] for tag in conll2003[\"train\"][0][\"pos_tags\"]]) # Decode the first sentence's POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caff1f2",
   "metadata": {},
   "source": [
    "| Word     | POS Tag | Meaning                          |\n",
    "|----------|---------|----------------------------------|\n",
    "| EU       | NNP     | Proper noun                      |\n",
    "| rejects  | VBZ     | Verb, 3rd person singular        |\n",
    "| German   | JJ      | Adjective                        |\n",
    "| call     | NN      | Noun                             |\n",
    "| to       | TO      | Infinitive marker                |\n",
    "| boycott  | VB      | Verb                             |\n",
    "| British  | JJ      | Adjective                        |\n",
    "| lamb     | NN      | Noun                             |\n",
    "| .        | .       | Punctuation                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a2797",
   "metadata": {},
   "source": [
    "## Chunk Tags  \n",
    "Chunk tags (also called shallow parsing) identify syntactic phrases in text that form coherent grammatical units. Unlike full parsing, chunking focuses on identifying non-overlapping phrases without hierarchical structure. Key phrase types include noun phrases (groups of words centered around a noun), verb phrases (groups containing a main verb), and prepositional phrases (groups starting with a preposition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92691dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "chunk_tag_names = conll2003[\"train\"].features[\"chunk_tags\"].feature.names\n",
    "print(conll2003[\"train\"][0]['tokens']) \n",
    "print([chunk_tag_names[tag] for tag in conll2003[\"train\"][0][\"chunk_tags\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b8133",
   "metadata": {},
   "source": [
    "| Word    | Chunk Tag | Meaning                   |\n",
    "|---------|-----------|---------------------------|\n",
    "| EU      | B-NP      | Beginning of noun phrase  |\n",
    "| rejects | B-VP      | Beginning of verb phrase  |\n",
    "| German  | B-NP      | Beginning of noun phrase  |\n",
    "| call    | I-NP      | Inside noun phrase        |\n",
    "| to      | B-VP      | Beginning of verb phrase  |\n",
    "| boycott | I-VP      | Inside verb phrase        |\n",
    "| British | B-NP      | Beginning of noun phrase  |\n",
    "| lamb    | I-NP      | Inside noun phrase        |\n",
    "| .       | O         | Outside any chunk         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf0f91",
   "metadata": {},
   "source": [
    "## NER Tags  \n",
    "Named Entity Recognition tags classify words or phrases that represent real-world objects into predefined categories. These tags follow the BIO (Begin-Inside-Outside) scheme to mark entity boundaries. The primary categories include persons, organizations, locations, and miscellaneous entities (dates, products, etc.), with each entity type having distinct B- (beginning) and I- (inside) tags for multi-word entities.<br>\n",
    "__These are the target labels we want to predict.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48653633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "ner_tag_names = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(conll2003[\"train\"][0]['tokens']) \n",
    "print([ner_tag_names[tag] for tag in conll2003[\"train\"][0][\"ner_tags\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff50df5",
   "metadata": {},
   "source": [
    "| Word    | NER Tag | Meaning                              |\n",
    "|---------|---------|--------------------------------------|\n",
    "| EU      | B-ORG   | Beginning of organization            |\n",
    "| rejects | O       | Not an entity                        |\n",
    "| German  | B-MISC  | Beginning of miscellaneous entity    |\n",
    "| call    | O       | Not an entity                        |\n",
    "| to      | O       | Not an entity                        |\n",
    "| boycott | O       | Not an entity                        |\n",
    "| British | B-MISC  | Beginning of miscellaneous entity    |\n",
    "| lamb    | O       | Not an entity                        |\n",
    "| .       | O       | Not an entity                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4f5a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "def word2features(sent, i, pos_tags, chunk_tags):\n",
    "    \"\"\"Feature extraction for each word in sentence\"\"\"\n",
    "    word = sent[i]\n",
    "    features = {\n",
    "        # Word features\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:], #extract the suffix\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        \n",
    "        # POS features\n",
    "        'pos': pos_tag_names[pos_tags[i]], #extract the word's pos tag\n",
    "        'pos[:2]': pos_tag_names[pos_tags[i]][:2], #extract the word's pos tag's category only e.g., 'NN' from 'NNP'\n",
    "        #extracting the category helps capture broader linguistic patterns\n",
    "        #It also helps the model understand that, for example, 'VBZ' and 'VBD' are somehow related (both verbs), not totally unrelated\n",
    "        \n",
    "        # Chunk features\n",
    "        'chunk': chunk_tag_names[chunk_tags[i]],\n",
    "        'chunk[:2]': chunk_tag_names[chunk_tags[i]][:2],\n",
    "    }\n",
    "    \n",
    "    # Context features\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            'prev_word': sent[i-1].lower(),\n",
    "            'prev_pos': pos_tag_names[pos_tags[i-1]],\n",
    "            'prev_chunk': chunk_tag_names[chunk_tags[i-1]],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of sentence\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        features.update({\n",
    "            'next_word': sent[i+1].lower(),\n",
    "            'next_pos': pos_tag_names[pos_tags[i+1]], \n",
    "            'next_chunk': chunk_tag_names[chunk_tags[i+1]],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of sentence\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01d7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    \"\"\"Convert dataset to features and labels\"\"\"\n",
    "    X, y = [], []\n",
    "    for tokens, pos_tags, chunk_tags, ner_tags in zip(\n",
    "        dataset[\"tokens\"],\n",
    "        dataset[\"pos_tags\"],\n",
    "        dataset[\"chunk_tags\"], \n",
    "        dataset[\"ner_tags\"]\n",
    "    ):\n",
    "        #crf expects X_train to be a list of lists of dictionaries\n",
    "        X.append([word2features(tokens, i, pos_tags, chunk_tags) for i in range(len(tokens))])\n",
    "        #crf expects y_train to be a list of lists of strings (target labels)\n",
    "        y.append([ner_tag_names[tag] for tag in ner_tags])\n",
    "        \n",
    "        #appending names not numerical labels for readability\n",
    "        #also, crf model converts it internally anyway, so even if we passed numerical labels it would work\n",
    "        #and it would return string labels as well when testing\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfc219",
   "metadata": {},
   "source": [
    "### Given this input:\n",
    "tokens = [[\"EU\", \"rejects\"], [\"Apple\", \"launched\"]]<br>\n",
    "pos_tags = [[22, 42], [22, 42]]<br>\n",
    "chunk_tags = [[11, 21], [11, 21]]<br>\n",
    "ner_tags = [[3, 0], [3, 0]]<br>\n",
    "\n",
    "zip(tokens, pos_tags, chunk_tags, ner_tags) → <br>\n",
    "[([\"EU\", \"rejects\"], [22, 42], [11, 21], [3, 0]),  # Sentence 0<br>\n",
    "    ([\"Apple\", \"launched\"], [22, 42], [11, 21], [3, 0])  # Sentence 1]<br>\n",
    "    \n",
    "#### How the for loop unpacks:\n",
    "for tokens, pos_tags, chunk_tags, ner_tags in zip(...):<br>\n",
    "#this results in \"tokens\" having a list of lists of tokens, each inner list contains one sentence's tokens, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e8f604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Train/Test Data\n",
    "X_train, y_train = prepare_data(conll2003[\"train\"])\n",
    "X_test, y_test = prepare_data(conll2003[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a34de04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRF Model Training\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs', #the optimizer\n",
    "    c1=0.1,  # L1 regularization: Encourages sparsity (drops useless features)\n",
    "    c2=0.01, # L2 regularization: Prevents large weights (smoother predictions)\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True  \n",
    "    # Allows all possible tag-to-tag transitions during training, even ones not seen in training data\n",
    "    # It also prevents model from crashing on rare transitions\n",
    "    # It lets regularization handle unlikely transitions (get low weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07f1ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.01,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CRF</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.01,\n",
       "    max_iterations=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.01,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed0993e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG      0.770     0.713     0.741      1661\n",
      "      B-MISC      0.816     0.765     0.790       702\n",
      "       B-PER      0.826     0.855     0.840      1617\n",
      "       I-PER      0.864     0.949     0.905      1156\n",
      "       B-LOC      0.853     0.812     0.832      1668\n",
      "       I-ORG      0.668     0.735     0.700       835\n",
      "      I-MISC      0.708     0.662     0.684       216\n",
      "       I-LOC      0.743     0.607     0.668       257\n",
      "\n",
      "   micro avg      0.803     0.797     0.800      8112\n",
      "   macro avg      0.781     0.762     0.770      8112\n",
      "weighted avg      0.803     0.797     0.799      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')  # Filter out 'O' tag\n",
    "\n",
    "print(flat_classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    labels=labels,\n",
    "    digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f293921d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Type Counts (True→Predicted):\n",
      "B-LOC→B-ORG: 151\n",
      "B-ORG→B-PER: 150\n",
      "B-ORG→O: 136\n",
      "B-ORG→B-LOC: 117\n",
      "B-PER→O: 85\n",
      "B-MISC→O: 80\n",
      "I-ORG→I-PER: 80\n",
      "B-PER→B-ORG: 66\n",
      "B-LOC→O: 66\n",
      "I-LOC→I-ORG: 64\n",
      "I-ORG→O: 64\n",
      "B-LOC→B-PER: 50\n",
      "B-ORG→B-MISC: 45\n",
      "B-PER→B-LOC: 43\n",
      "I-PER→I-ORG: 43\n",
      "B-MISC→B-ORG: 30\n",
      "B-MISC→B-PER: 27\n",
      "B-LOC→B-MISC: 25\n",
      "I-ORG→I-LOC: 24\n",
      "I-MISC→O: 23\n",
      "B-ORG→I-ORG: 22\n",
      "I-ORG→B-ORG: 21\n",
      "I-LOC→I-PER: 19\n",
      "B-MISC→B-LOC: 19\n",
      "I-MISC→I-PER: 18\n",
      "I-ORG→I-MISC: 17\n",
      "B-PER→I-PER: 16\n",
      "B-LOC→I-ORG: 16\n",
      "I-LOC→O: 16\n",
      "I-MISC→I-ORG: 13\n",
      "B-PER→B-MISC: 10\n",
      "I-ORG→B-PER: 9\n",
      "I-MISC→B-MISC: 8\n",
      "B-PER→I-ORG: 8\n",
      "I-ORG→B-LOC: 8\n",
      "I-PER→O: 7\n",
      "I-PER→B-PER: 7\n",
      "B-ORG→I-PER: 5\n",
      "I-MISC→I-LOC: 5\n",
      "I-LOC→B-LOC: 4\n",
      "I-ORG→B-MISC: 3\n",
      "B-MISC→I-MISC: 3\n",
      "I-PER→I-LOC: 2\n",
      "I-PER→I-MISC: 2\n",
      "B-MISC→I-PER: 2\n",
      "B-MISC→I-ORG: 2\n",
      "B-LOC→I-PER: 2\n",
      "I-MISC→B-LOC: 2\n",
      "I-MISC→B-PER: 1\n",
      "B-PER→I-MISC: 1\n",
      "B-ORG→I-LOC: 1\n",
      "B-LOC→I-LOC: 1\n",
      "B-PER→I-LOC: 1\n",
      "I-LOC→I-MISC: 1\n",
      "B-ORG→I-MISC: 1\n",
      "B-LOC→I-MISC: 1\n",
      "\n",
      "Example Errors in Context:\n",
      "\n",
      "Sentence 1: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
      "  - Word: 'CHINA' (True: B-PER, Pred: B-LOC)\n",
      "\n",
      "Sentence 2: AL-AIN , United Arab Emirates 1996-12-06\n",
      "  - Word: 'United' (True: B-LOC, Pred: B-ORG)\n",
      "  - Word: 'Arab' (True: I-LOC, Pred: I-ORG)\n",
      "  - Word: 'Emirates' (True: I-LOC, Pred: I-ORG)\n",
      "\n",
      "Sentence 3: But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .\n",
      "  - Word: 'Uzbekistan' (True: B-LOC, Pred: B-ORG)\n",
      "\n",
      "Sentence 4: China controlled most of the match and saw several chances missed until the 78th minute when Uzbek striker Igor Shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing Chinese keeper and into an empty net .\n",
      "  - Word: 'Uzbek' (True: B-MISC, Pred: B-PER)\n",
      "\n",
      "Sentence 5: Defender Hassan Abbas rose to intercept a long ball into the area in the 84th minute but only managed to divert it into the top corner of Bitar 's goal .\n",
      "  - Word: 'Hassan' (True: B-PER, Pred: I-PER)\n",
      "  - Word: 'Bitar' (True: B-PER, Pred: B-ORG)\n",
      "\n",
      "Sentence 6: Bitar pulled off fine saves whenever they did .\n",
      "  - Word: 'Bitar' (True: B-PER, Pred: B-ORG)\n",
      "\n",
      "Sentence 7: RUGBY UNION - CUTTITTA BACK FOR ITALY AFTER A YEAR .\n",
      "  - Word: 'CUTTITTA' (True: B-PER, Pred: O)\n",
      "  - Word: 'ITALY' (True: B-LOC, Pred: O)\n",
      "\n",
      "Sentence 8: ROME 1996-12-06\n",
      "  - Word: 'ROME' (True: B-LOC, Pred: O)\n",
      "\n",
      "Sentence 9: Cuttitta , who trainer George Coste said was certain to play on Saturday week , was named in a 21-man squad lacking only two of the team beaten 54-21 by England at Twickenham last month .\n",
      "  - Word: 'Cuttitta' (True: B-PER, Pred: B-LOC)\n",
      "\n",
      "Sentence 10: Cuttitta announced his retirement after the 1995 World Cup , where he took issue with being dropped from the Italy side that faced England in the pool stages .\n",
      "  - Word: 'Cuttitta' (True: B-PER, Pred: B-ORG)\n",
      "  - Word: '1995' (True: B-MISC, Pred: O)\n",
      "  - Word: 'World' (True: I-MISC, Pred: B-MISC)\n"
     ]
    }
   ],
   "source": [
    "#Error Analysis\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_errors(y_true, y_pred, dataset):\n",
    "    \"\"\"Print full sentences with errors and error statistics\"\"\"\n",
    "    error_counts = defaultdict(int)\n",
    "    error_examples = defaultdict(list)\n",
    "    \n",
    "    for sent_idx in range(len(y_true)):\n",
    "        tokens = dataset[\"test\"][sent_idx][\"tokens\"]\n",
    "        true_tags = y_true[sent_idx]\n",
    "        pred_tags = y_pred[sent_idx]\n",
    "        \n",
    "        errors_in_sent = []\n",
    "        for i in range(len(true_tags)):\n",
    "            if true_tags[i] != pred_tags[i] and true_tags[i] != 'O':\n",
    "                error_key = f\"{true_tags[i]}→{pred_tags[i]}\"\n",
    "                error_counts[error_key] += 1\n",
    "                errors_in_sent.append(\n",
    "                    f\"Word: '{tokens[i]}' (True: {true_tags[i]}, Pred: {pred_tags[i]})\"\n",
    "                )\n",
    "        \n",
    "        if errors_in_sent:\n",
    "            error_examples[\"sentences\"].append({\n",
    "                \"sentence\": \" \".join(tokens),\n",
    "                \"errors\": errors_in_sent\n",
    "            })\n",
    "    \n",
    "    # Print error statistics\n",
    "    print(\"\\nError Type Counts (True→Predicted):\")\n",
    "    for error, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{error}: {count}\")\n",
    "    \n",
    "    # Print example sentences with errors\n",
    "    print(\"\\nExample Errors in Context:\")\n",
    "    for i, example in enumerate(error_examples[\"sentences\"][:10]):  # First 10 examples\n",
    "        print(f\"\\nSentence {i+1}: {example['sentence']}\")\n",
    "        for error in example[\"errors\"]:\n",
    "            print(f\"  - {error}\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_errors(y_test, y_pred, conll2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e34c3c",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "The model achieved an F1-score of 80% on the test set. While this demonstrates strong performance for a classical machine learning technique, a deeper error analysis reveals specific challenges that are compounded by the known limitations of the CoNLL-2003 dataset. The model frequently confused locations with organizations (e.g., 'United Arab Emirates' as an organization, 'Uzbekistan' as an organization) and organizations with persons (e.g., 'Bitar' as an organization).<br>\n",
    "Crucially, some observed \"errors\" by the model, such as predicting 'CHINA' as a location (B-LOC) when __the original dataset annotates it as a person (B-PER)__ in a sentence like \"SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT.\", point directly to intrinsic annotation mistakes within the CoNLL-2003 __ground truth__ itself.<br>\n",
    "Furthermore, a significant number of errors involved missing entities entirely (True→O, such as 'CUTTITTA', 'ITALY', and 'ROME' being missed), indicating difficulty in identifying boundaries or recognizing less common entities. These types of discrepancies underscore that a portion of the discrepancies between model predictions and the gold standard may stem from the dataset's inherent noise, rather than solely from model limitations. Future work could benefit from evaluation on corrected versions of the dataset or by incorporating robust error detection mechanisms during training to mitigate the impact of such annotation inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ecf68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
